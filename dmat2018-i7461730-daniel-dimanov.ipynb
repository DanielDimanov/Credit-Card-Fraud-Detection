{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"_kg_hide-output":false},"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"../input/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n#Visualisation libraries\nimport seaborn as sns\n\n#Oversampling libraries\nfrom numpy import genfromtxt\nfrom sklearn.decomposition import PCA #dimensionality reduction\nfrom imblearn.over_sampling import ADASYN #Oversampling \n\n\nimport matplotlib.pyplot as plt #plotting data\n\nimport os\nprint(os.listdir(\"../input\"))\n\n# Any results you write to the current directory are saved as output.","execution_count":null,"outputs":[]},{"metadata":{"_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","trusted":true},"cell_type":"code","source":"card_data = pd.read_csv(\"../input/creditcardfraud/creditcard.csv\")\ncard_data.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"136a3d3530fb587a94dab74a50aff699047973f8"},"cell_type":"markdown","source":"**Data Statististics**"},{"metadata":{"trusted":true,"_uuid":"b9fa5b7f794dd3861f5cddaf5ec87f80101c7e8d"},"cell_type":"code","source":"card_data.describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"146f7800c9ab22c1678d692c1bbe4023556f2dd1"},"cell_type":"markdown","source":"Fraud statistics"},{"metadata":{"trusted":true,"_uuid":"ed12a76855a0664745e25f18f7047214b726dfd7"},"cell_type":"code","source":"card_data[card_data.Amount==0]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"89c77ecff1adc81cccea7ee0a24fad009acd886e"},"cell_type":"code","source":"card_data.Amount[card_data.Class == 1].describe()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"5eb0d48762386ea8cf2d9c56ebbba2f98a821d9b"},"cell_type":"markdown","source":"Non fraud statistics"},{"metadata":{"trusted":true,"_uuid":"1d2b1f795fbff280d0f41aa0b010c3df1d12ec62"},"cell_type":"code","source":"card_data.Amount[card_data.Class == 0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"37aa8ff3232efd82f3ae5295632e4b095e78622b"},"cell_type":"markdown","source":"Very similar, but max is different and mean is smaller.  Yet the data is highly imbalanced - 492 fraund transactions and 284315 non fraud transactions."},{"metadata":{"trusted":true,"_uuid":"1409f8fa4d3e4e6f243fe7639462f1373dec9964"},"cell_type":"code","source":"#Fraud\ncard_data[card_data.Class == 1].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"884b6784ab1f86e5d898f401bc17a07500422b3f"},"cell_type":"code","source":"#Genuine\ncard_data[card_data.Class == 0].describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"119b2f458b44dd9592de8649e8e05b6c87915782"},"cell_type":"code","source":"pd.plotting.parallel_coordinates(card_data.sample(1000), \"Class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"886c546ad300b8329b1b49a109567da018b38d72"},"cell_type":"code","source":"card_data_no_time_and_amount=card_data.drop(\"Time\",axis=1)\ncard_data_no_time_and_amount=card_data_no_time_and_amount.drop(\"Amount\",axis=1)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"1cf5e07c7b3ea9e85c8a04f8558ce70564a05415"},"cell_type":"code","source":"pd.plotting.parallel_coordinates(card_data_no_time_and_amount.sample(1000), \"Class\", color=['g','m'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"63bee19ab652fc2d0738b0f3a0817969be65c86c"},"cell_type":"code","source":"#Check for null values, which can cause problems later\ncard_data.isnull().sum()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5ce61fc7a0b0c049097c5457905bbdbf9a4371c9"},"cell_type":"markdown","source":"**2. Plotting the data**"},{"metadata":{"trusted":true,"_uuid":"90b4588d80a732201ce74ad0686cdf27f9125930"},"cell_type":"code","source":"graph, (fraud_gr, non_fraud_gr) = plt.subplots(2, 1, sharex=True, figsize=(20,6))\n\ncats = 60 #numbebrs of categories/bars\n\nfraud_gr.hist(card_data.Time[card_data.Class == 1], cats)\nfraud_gr.set_title('Fraud')\n\nnon_fraud_gr.hist(card_data.Time[card_data.Class == 0], cats)\nnon_fraud_gr.set_title('Non-Fraud')\n\nplt.xlabel('Time (sec)')\nplt.ylabel('Transaction count')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a25859c82dcc6c5857239a7acf8ca59782c45623"},"cell_type":"code","source":"import seaborn as sns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"5bbc7f381383061505f2b16d00e9e6c71a03f42d"},"cell_type":"code","source":"matrix_correlation = card_data.corr()\nfig = plt.figure(figsize = (12, 9))\n\nsns.heatmap(matrix_correlation, vmax = .8, square = True)\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"4b1ab267d632c70e18056ec91d25ab08f544c3c2"},"cell_type":"code","source":"sns.pairplot(card_data.sample(1000), hue=\"Class\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ca33693822247826d83d36502989aabcd5635bde"},"cell_type":"code","source":"pd.plotting.andrews_curves(card_data_no_time_and_amount.sample(10000), \"Class\", color=['g','r'])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6cdd425c40581103ae05e1cd2bb65f158b14302"},"cell_type":"code","source":"card_data.keys()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"3549a6c8b31acd2c222c45658542aa35cdbb6c9e"},"cell_type":"markdown","source":"**Preparing for Oversampling**"},{"metadata":{"trusted":true,"_uuid":"475c78b187c53d97f8f1cd3ea66a2140ed3d3ee9"},"cell_type":"code","source":"from  sklearn.model_selection import train_test_split\nimport keras\ndef data_preparation(x): \n    x_data= x.iloc[:,x.columns != \"Class\"]\n    x_labels=x.iloc[:,x.columns==\"Class\"]\n    x_labels_norm = keras.utils.to_categorical(x_labels,num_classes=None)\n    X_train, X_test, y_train, y_test = train_test_split(x_data,x_labels_norm,test_size=0.2,random_state=0)\n    return(X_train, X_test, y_train, y_test)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9db2fea4da4f099faee0593e87f99918b167fdd7"},"cell_type":"code","source":"data = card_data","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"688af68fca797cb6fde5a1b82a9ab2a09ce45b03"},"cell_type":"markdown","source":"I use the variable *data* to operate on from now on, because it boosts coding efficiency"},{"metadata":{"trusted":true,"_uuid":"07342f9a84898bdfea168252e874d1c9f37a18f3"},"cell_type":"code","source":"data.drop([\"Time\"],axis=1,inplace=True)\ndata.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"78bc0135efeaf6e71743c8ce3cc7ed1f2279edfa"},"cell_type":"code","source":"data.columns[:-1]","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ee66f669313d985dbe6ab4c251068282a8e05525"},"cell_type":"markdown","source":"*Time* is dropped, because if it is considered the whole structure of the classifier has to be adjusted for time series, but the data is not time centered, so I decided to leave time out"},{"metadata":{"trusted":true,"_uuid":"c0589f8e18729eb462f66a2e5be646bb4b2d872f"},"cell_type":"code","source":"data['Class'].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a56942a5014778bc93545ecc3aaeb95d766339aa"},"cell_type":"code","source":"X_train, X_test, y_train, y_test=data_preparation(data)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b02b6d30cbc5fd3692a0afd57aa788e00f42c679"},"cell_type":"markdown","source":"Test sample size is 20%. As suggested in \"*Recurrent Neural Networks and Robust Time Series Prediction*\" by \nJ. T. Connor, R.  Martin,  and L. E. Atlas. 30% split was considered, but after achieving worse results the 80/20 split was chosen."},{"metadata":{"trusted":true,"_uuid":"906addd2d7cbb1681034bc5c8299af75d0c80b37"},"cell_type":"code","source":"pca = PCA(n_components=2)\ndata_2d = pd.DataFrame(pca.fit_transform(data))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"9f27c3d27b74038b30cb6bca72bc640f6f50057c"},"cell_type":"code","source":"data_2d","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e6a5427131242cc45723298a095d023ae12b2468"},"cell_type":"code","source":"data_2d= pd.concat([data_2d, data['Class']], axis=1)\ndata_2d.columns = ['x', 'y', 'Class']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"35bbddcf6cfd76638feff97ad049a4c2b8b4a20a"},"cell_type":"code","source":"sns.lmplot(x=\"x\",y=\"y\",data=data_2d, fit_reg=False, hue='Class')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"ec4b45b60224d58fc1eca0fa6e66d7b43f7f175f"},"cell_type":"markdown","source":"**Oversampling**"},{"metadata":{"trusted":true,"_uuid":"75dccf5cb54f4a543f960468654d43d1a58b0360"},"cell_type":"code","source":"ada = ADASYN()\nX_resampled, y_resampled = ada.fit_sample(X_train, y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"a04a8fa4eaebe8e20eeb1ba0bac65f260ac53941"},"cell_type":"code","source":"unique, counts = np.unique(y_train, return_counts=True)\ndict(zip(unique, counts))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0bb478f9ad996aa0dc2464368c32724ff96b14ce"},"cell_type":"code","source":"data_oversampled = pd.concat([pd.DataFrame(X_resampled), pd.DataFrame(y_resampled)], axis=1)\ndata_oversampled.columns = data.columns","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"73e6b894f163932f9d8cdbf9f748c9bfaf0915da"},"cell_type":"code","source":"data_oversampled[\"Class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"f353419fcf7eab4d3766f0568508bbefe75d0161"},"cell_type":"code","source":"data_2d_oversampled = pd.DataFrame(pca.transform(data_oversampled))\ndata_2d_oversampled= pd.concat([data_2d_oversampled, data_oversampled['Class']], axis=1)\ndata_2d_oversampled.columns = ['x', 'y', 'Class']","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"fe43c55c0ffaef483d1c992a5fff79e102145f05"},"cell_type":"markdown","source":"**Display the oversampled data frame**"},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"d6086b63dfcf081cc24846c3bb0d5ab437459297"},"cell_type":"code","source":"data_2d_oversampled","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"b20e4425092a8fd67bfb3ebe182df3d3965044e5"},"cell_type":"code","source":"sns.lmplot(x=\"x\",y=\"y\",data=data_2d_oversampled, fit_reg=False, hue='Class')","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"6a5d96bdd8adba96975da443225721c664f5651b"},"cell_type":"markdown","source":"Looks similar enough, so the oversampling was successful!"},{"metadata":{"trusted":true,"_uuid":"3e77e4a10d938399c9946d153abcb5d6e96624b5"},"cell_type":"markdown","source":"**Design of MLP**"},{"metadata":{"trusted":true,"_uuid":"aa250f49460e5cfb448b3166e0c81e0c70a50eb6"},"cell_type":"code","source":"y= data_oversampled['Class'].astype('category').cat.codes","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"310d425cdeb19d9143027978938f23932f89df2e"},"cell_type":"code","source":"Y = keras.utils.to_categorical(y,num_classes=None)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"0d757ab0ad59816b789490d7a7c9a05f3a8a33f5"},"cell_type":"code","source":"X= data_oversampled.iloc[:,0:29].values","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2fcbc0e2fc721f00683bb689efb633b73f890d14"},"cell_type":"code","source":"X_train, X_val, y_train, y_val = train_test_split(X,Y,test_size=0.3,random_state=0)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"464b19a607a17445c351172f1e0b0bd047bf722a"},"cell_type":"markdown","source":"**Undersampling to verify results**"},{"metadata":{"trusted":true,"_uuid":"24f15a3a319f94d85e21a8f91e9e666a829be1e4"},"cell_type":"code","source":"from numpy import argmax\ntest_set_class=argmax(y_test, axis=1)\ntest_set_data=pd.DataFrame(X_test.values)\ntest_set_data.columns=X_test.columns\nunique, counts = np.unique(test_set_class, return_counts=True)\ntest_set_class_df = pd.DataFrame({'Class':test_set_class})\nframes =[test_set_data,test_set_class_df]\ntest_set = pd.concat(frames, axis=1)\nprint(dict(zip(unique, counts))) ","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"scrolled":true,"_uuid":"6f426e41622874d75cbe7d6c05c9b2cdba0a7c9c"},"cell_type":"code","source":"test_set.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"95d47017eca4269e0050fa01f13c1f390ffc2215"},"cell_type":"code","source":"fraud_indices= np.array(test_set[test_set.Class==1].index)\nnon_fraud_indices = np.array(test_set[test_set.Class==0].index)\ndata_non_fraud = test_set[test_set[\"Class\"]==0]\ndata_fraud = test_set[test_set[\"Class\"]==1]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"415ba9520456d4f0dba94254cb6a2f1606435802"},"cell_type":"code","source":"from sklearn.utils import resample\ndata_non_fraud_downsampled = resample(data_non_fraud,replace=False,n_samples=len(fraud_indices))\ndata_downsampled = pd.concat([data_non_fraud_downsampled, data_fraud])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"ece930d9b9932f1ae4224795134937d8343a872c"},"cell_type":"code","source":"data_downsampled[\"Class\"].value_counts()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"52678ab3e8e017aba73c06e975cdaa2d04f51586"},"cell_type":"code","source":"#Now from the undersampled set I can take test values \ntest_set_downsampled_data= data_downsampled.iloc[:,data_downsampled.columns != \"Class\"]\ntest_set_downsampled_labels=data_downsampled.iloc[:,data_downsampled.columns==\"Class\"]\ntest_set_downsampled_labels_norm = keras.utils.to_categorical(test_set_downsampled_labels,num_classes=None)\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"23811dba4e682bea6ba4545bb80578b13cbdb4b0"},"cell_type":"code","source":"X_test_downsampled= test_set_downsampled_data\ny_test_downsampled= test_set_downsampled_labels_norm","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b140a45f56c167a7dd757351864f53f1f1229be0"},"cell_type":"markdown","source":"**Custom metrics**"},{"metadata":{"trusted":true,"_uuid":"b4fb8fc0305d88941a9f22cb0cc6dfabc989aae5"},"cell_type":"code","source":"from keras import backend as K\n\ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        pp = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = tp / (pp + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        tp = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        pp = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = tp / (pp + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)/(precision+recall+K.epsilon()))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b399be30459fde8faddce3d9ab1e6291fdd72ce3"},"cell_type":"markdown","source":"**Test model**"},{"metadata":{"trusted":true,"_uuid":"1ec7b2eadd03169c65b835902891e276e0cf2f0c"},"cell_type":"code","source":"model = keras.Sequential()\nmodel.add(keras.layers.Dense(29, input_shape=(29,), activation='relu'))\nmodel.add(keras.layers.Dense(3, input_shape=(3,), activation='tanh'))\nmodel.add(keras.layers.Dense(2, activation='softmax'))\nmodel.compile(keras.optimizers.Adam(lr=0.001),'binary_crossentropy',metrics=['accuracy',f1])","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"305a94915954b3263680e1e2bbc29355ccdbb163","_kg_hide-output":true},"cell_type":"code","source":"history= model.fit(X_train, y_train, validation_data=(X_val,y_val), epochs=200, batch_size=5000)","execution_count":null,"outputs":[]},{"metadata":{"_kg_hide-input":true,"trusted":true,"_uuid":"cabb287e939a5e737136649ed0178de33e2d8337"},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"e48ec88ed54168ac9fa7e8c307f6f9e07130a136","scrolled":true},"cell_type":"code","source":"model.evaluate(X_test,y_test)[2]","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"063bebb31a2bde63f0e3c2b20bae098e5aabd2fd"},"cell_type":"code","source":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\ny_pred= model.predict(X_test)\nfpr, tpr, thresholds = roc_curve(argmax(y_test, axis=1), argmax(y_pred, axis=1))\nauc_score = auc(fpr, tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"6abe947a61412d1c35c9dd9fe25001c865d62685"},"cell_type":"code","source":"plt.figure(1)\nplt.plot([0, 1], [0, 1], '--')\nplt.plot(fpr, tpr, label='Control (AUC = {:.3f})'.format(auc_score), color='g')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"72b2ed96dd335cda1cc5d136e4c5a3ff0a050df3"},"cell_type":"markdown","source":"I tested it with neurons 3-32 in the first hidden layer (as a side experimental arm) and it makes no signifant difference, so I left it with less parameters to conserve computing power\nNow I see when the model converges"},{"metadata":{"trusted":true,"_uuid":"b587aef49ca3aeb5773e8199838e11770702d3f7"},"cell_type":"code","source":"history.history.keys()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"cdce22dca551d3897c42f0b77d464e9234f198ce"},"cell_type":"code","source":"zoom=60\nzoom-=1\nplt.plot(history.history['f1'][0:zoom])\nplt.plot(history.history['val_f1'][0:zoom])\nplt.plot(history.history['loss'][0:zoom])\nplt.plot(history.history['val_loss'][0:zoom])\nplt.title('Model Performance')\nplt.ylabel('performance')\nplt.xlabel('epoch')\nplt.legend(['train_f1', 'val_f1', 'train_loss','val_loss'], loc='center right')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b5f173cb05112413bdcc53194211acee4dbe3362"},"cell_type":"markdown","source":"We can clearly see that in 25 epochs the model reaches the early convergance, but for safety and a bit more gain 50 epochs should be sufficient "},{"metadata":{"trusted":true,"_uuid":"23ffe8859f0b660812fea9fc5739bf603fefc33a"},"cell_type":"code","source":"#Making sure the validation dataset is balanced, so accuracy is a relevant metric. \nunique, counts = np.unique(y_val, return_counts=True)\ndict(zip(unique, counts)) ","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"bb16c329ff9b511e181e2604075b8de56001c5f1"},"cell_type":"markdown","source":"**Control Model**"},{"metadata":{"trusted":true,"_uuid":"26c4d217e099b1b592d57d61b189c18e30b02f4b","scrolled":true,"_kg_hide-output":true},"cell_type":"code","source":"from sklearn.model_selection import StratifiedKFold\nskf = StratifiedKFold(n_splits=5, shuffle=True)\nresults_control_auc = []\nresults_control_fpr = []\nresults_control_tpr = []\n# results_control_f1 = []\n\nfor i in range(0,7):\n    for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n        X_train_local, X_val_local = X[train_indices], X[val_indices]\n        y_train_local, y_val_local = Y[train_indices], Y[val_indices]\n        model = keras.Sequential()\n        model.add(keras.layers.Dense(29, input_shape=(29,), activation='relu'))\n        model.add(keras.layers.Dense(3, input_shape=(3,), activation='tanh'))\n        model.add(keras.layers.Dense(2, activation='softmax'))\n        model.compile(keras.optimizers.Adam(lr=0.04),'binary_crossentropy',metrics=['accuracy',f1])\n        # I tried using f1 score, but because of micro averages it was almost equal to the accuracy, but I decided to stick with f1 score\n        model.fit(X_train_local, y_train_local, validation_data=(X_val_local,y_val_local), epochs=50, batch_size=5000)\n#         model_results = model.evaluate(X_test, y_test)\n#         model_results_2=model.evaluate(X_test,test_set_downsampled_labels) \n        y_pred= model.predict(X_test)\n        fpr, tpr, thresholds = roc_curve(argmax(y_test, axis=1), argmax(y_pred, axis=1))\n        \n        auc_score = auc(fpr, tpr)\n#Testing if the cat.codes is giving me false results and the answer is no and everything works surprisingly well\n#         f1_score = model_results[2]\n        results_control_auc.append(auc_score)\n        results_control_fpr.append(fpr)\n        results_control_tpr.append(tpr)\n#         results_control_f1.append(f1_score)\n        print (\"AUC of last iteration: \" + str(auc_score))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b3ca9cdf227df5e1e8424035005becf2516f016e"},"cell_type":"markdown","source":"**Experimental model**"},{"metadata":{"trusted":true,"_uuid":"e8226c876ebb8ab88c4050038b133d8fb29c9610","scrolled":true,"_kg_hide-output":true},"cell_type":"code","source":"results_experimental_auc = []\nresults_experimental_fpr = []\nresults_experimental_tpr = []\nfor i in range(0,7):\n    for index, (train_indices, val_indices) in enumerate(skf.split(X, y)):\n        print(\"Iteration: \" +str((index+1)+(5*(i))))\n        X_train_local, X_val_local = X[train_indices], X[val_indices]\n        y_train_local, y_val_local = Y[train_indices], Y[val_indices]\n        model = keras.Sequential()\n        model.add(keras.layers.Dense(29, input_shape=(29,), activation='relu'))\n        model.add(keras.layers.Dense(16, input_shape=(16,), activation='relu'))\n        model.add(keras.layers.Dense(3, input_shape=(3,), activation='tanh'))\n        model.add(keras.layers.Dense(2, activation='softmax'))\n        #model.compile(keras.optimizers.Adam(lr=0.04),'binary_crossentropy',metrics=['accuracy'])\n        #Since the test dataset is undersampled and accuracy is equal to the f1 score, I decided to keep just the f1 score,\n        #but it will be equally right to speak of the accuracy comparision\n        model.compile(keras.optimizers.Adam(lr=0.04),'binary_crossentropy',metrics=[f1]) \n        model.fit(X_train_local, y_train_local, validation_data=(X_val_local,y_val_local), epochs=50, batch_size=5000)\n        y_pred= model.predict(X_test)\n        fpr, tpr, thresholds = roc_curve(argmax(y_test, axis=1), argmax(y_pred, axis=1))\n        auc_score = auc(fpr, tpr)\n        results_experimental_auc.append(auc_score)\n        results_experimental_fpr.append(fpr)\n        results_experimental_tpr.append(tpr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"45f81d8e0c017fdac9d86d222f1850ec2a5bda1c"},"cell_type":"code","source":"pd.DataFrame(results_control_auc).to_csv('results_control_auc.csv', index=False)\npd.DataFrame(results_control_fpr).to_csv('results_control_fpr.csv', index=False)\npd.DataFrame(results_control_tpr).to_csv('results_control_tpr.csv', index=False)\n\npd.DataFrame(results_experimental_auc).to_csv('results_experimental_auc.csv', index=False)\npd.DataFrame(results_experimental_fpr).to_csv('results_experimental_fpr.csv', index=False)\npd.DataFrame(results_experimental_tpr).to_csv('results_experimental_tpr.csv', index=False)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0f4dce37fbb5550558d2bbb086b124b36690ebb"},"cell_type":"markdown","source":"The K-fold is a cross-validation technique, where the classifier is exposed to the whole training set, while leaving different parts of it hidden for cross-validation. On every iteration the cross-validation set from last iteration is used for training and another part is chosed for cross-validation. n_splits of 5 were chosed, because as in [TODO] it proves to be promissing split."},{"metadata":{"_uuid":"8009a5fe86a11245170c0ae3e781ab31922848a4"},"cell_type":"markdown","source":"**Results analysis**"},{"metadata":{"trusted":true,"_uuid":"b0580a8147c1f8f4b622384a7fad73858753960d"},"cell_type":"code","source":"results_control_auc=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_control_auc.csv\")\nresults_control_tpr=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_control_tpr.csv\")\nresults_control_fpr=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_control_fpr.csv\")\n\nresults_experimental_auc=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_experimental_auc.csv\")\nresults_experimental_tpr=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_experimental_tpr.csv\")\nresults_experimental_fpr=pd.read_csv(\"../input/dmat2018-i7461730-daniel-dimanov/results_experimental_fpr.csv\")","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"10ef83c4cdc3a794d439ca07517394a008ec3af1"},"cell_type":"code","source":"control_fprs=results_control_fpr.values\ncontrol_tprs=results_control_tpr.values\ncontrol_aucs=results_control_auc.values\nexp_tprs=results_experimental_tpr.values\nexp_fprs=results_experimental_fpr.values\nexp_aucs=results_experimental_auc.values\nplt.figure(1)\nplt.plot([0, 1], [0, 1], '--')\nfor i in range(0,len(control_fprs)-1):\n    if i==0:\n        plt.plot(control_fprs[i], control_tprs[i], label='Control (AUC ='+str(results_control_auc.mean()[0])+\")\", color='g')\n        plt.plot(exp_fprs[i], exp_tprs[i], label='Experimental (AUC = '+ str(results_experimental_auc.mean()[0]) + \")\", color='r')\n    else:\n        plt.plot(control_fprs[i], control_tprs[i], color='g')\n        plt.plot(exp_fprs[i], exp_tprs[i], color='r')\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"d4e072412c340fecac8e753f78f0c3008657da41"},"cell_type":"code","source":"mean_control_auc = results_control_auc.mean()\nprint(\"Mean Control AUC: {}\".format(mean_control_auc))\n\nmean_experimental_auc = results_experimental_auc.mean()\nprint(\"Mean Experimental AUC: {}\".format(mean_experimental_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"039a70707594704c416ea8672f0607bdc36b15a9"},"cell_type":"code","source":"std_control_auc = results_control_auc.std()\nprint(\"Standard Deviation of Control F1-score Results: {}\".format(std_control_auc))\n\nstd_experimental_auc = results_experimental_auc.std()\nprint(\"Standard Deviation of Experimental F1-score Results: {}\".format(std_experimental_auc))","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"bc71133b27abac84268631f4ca28f58d1b1c3f13"},"cell_type":"code","source":"results_auc= pd.concat([results_control_auc, results_experimental_auc], axis=1)\nresults_auc.columns = ['Control', 'Experimental']","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"9f3735fbf6b8e0a4b04ea548d8d5718fa0a3855d"},"cell_type":"code","source":"results_auc.boxplot(showfliers=False)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"fe0ea6208d6b17a34ea2d040f8532d9640ee82c2"},"cell_type":"code","source":"results_auc.hist(density=True)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"2a72317ac6d6199247983376fabe2dbaf5942694","_kg_hide-output":false},"cell_type":"code","source":"from scipy import stats\n\nalpha = 0.05;\n\ns, p = stats.normaltest(results_control_auc)\nprint(p)\nif p < alpha:\n    print('Control data is not normal')\nelse:\n    print('Control data is normal')\n\ns, p = stats.normaltest(results_experimental_auc)\nprint(p)\nif p < alpha:\n    print('Experimental data is not normal')\nelse:\n    print('Experimental data is normal')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"22c98bb8ab4088a086ffccb8cbbffa399428390c"},"cell_type":"code","source":"pearson_coef, p_value = stats.pearsonr(results_control_auc, results_experimental_auc) #define the columns to perform calculations on\n\nif p_value < 0.05 and pearson_coef!=0:\n    if(pearson_coef>0):\n        print('null hypothesis rejected, significant difference between the data-sets with tendency for the control arm to be better')\n    else:\n        print('null hypothesis rejected, significant difference between the data-sets with tendency for the experimental arm to be better')\nelse:\n  print('null hypothesis accepted, no significant difference between the data-sets')","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"319cc43bf6c3993e7f7d28845a374c67bb149555"},"cell_type":"code","source":"results_control_auc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"3e7fc0fde3667f459e3740a6397acd2efa891845"},"cell_type":"code","source":"results_experimental_auc.describe()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true,"_uuid":"c246b04531f1158b14c9a386ef06e5002aea36b6"},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":1}